{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6ff90ee-6dcc-4cba-8d8f-c7e3e9c2ab7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ana\\envs\\pytorch1.7\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "\n",
    "#引入脚本文件\n",
    "from data_utils import load_all    #加载数据\n",
    "from evaluate import metrics    #模型评测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d44b1fe6-938a-4f07-afbe-c8d77b09e8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config():\n",
    "    def __init__(self):\n",
    "        self.DEBUG = False\n",
    "        self.factor_num = 32\n",
    "        self.num_layers = 3\n",
    "        self.dropout = 0.0\n",
    "        self.lr = 0.0001\n",
    "        self.batch_size = 128\n",
    "        self.num_ng = 5 #训练时每个正例的负采样数\n",
    "        self.test_num_ng = 100 #测试时的负采样\n",
    "        self.epochs = 20 if self.DEBUG else 2\n",
    "        self.out = 1\n",
    "        self.top_k = 10\n",
    "        self.model = 'GMF'\n",
    "        self.model_path = './temp/'\n",
    "        self.trainRatingPath = 'data/train.rating'\n",
    "        self.testNegativePath = 'data/test.negative'\n",
    "        self.device = torch.device('cpu')\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.device('cuda')\n",
    "        if self.model == 'NeuMF-pre':\n",
    "            assert os.path.exists(model_path + 'GMF.pth'), 'lack of GMF model'\n",
    "            assert os.path.exists(model_path + 'MLP.pth'), 'lack of MLP model'\n",
    "            self.GMF_model = torch.load(model_path + 'GMF.pth')\n",
    "            self.MLP_model = torch.load(model_path + 'MLP.pth')\n",
    "        else:\n",
    "            self.GMF_model = None\n",
    "            self.MLP_model = None\n",
    "args = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88a6166d-2a17-4bbb-b4b6-cc60ec79471c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, user_num ,item_num, train_mat = load_all(args.trainRatingPath, args.testNegativePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a23517b2-a4dd-4311-b2b1-d30ad68478b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCF(nn.Module):\n",
    "    def __init__(self, user_num, item_num, factor_num, num_layers,\n",
    "            dropout, model, GMF_model=None, MLP_model=None):\n",
    "        super(NCF, self).__init__()\n",
    "        \"\"\"\n",
    "        user_num: 数据集中用户数量;\n",
    "        item_num: 数据集中商品数量;\n",
    "        factor_num: 最终形成的预测向量维度;\n",
    "        num_layers: MLP的层数;\n",
    "        dropout: 丢失率;\n",
    "        model: 'MLP', 'GMF', 'NeuMF-end', and 'NeuMF-pre';\n",
    "        GMF_model:是否有预训练的 GMF，若有，值为路径;\n",
    "        MLP_model: 是否有预训练的 MLP，若有，值为路径.\n",
    "        \"\"\"\n",
    "        self.dropout = dropout\n",
    "        self.model = model\n",
    "        self.GMF_model = GMF_model\n",
    "        self.MLP_model = MLP_model\n",
    "        self.embed_user_GMF = nn.Embedding(user_num, factor_num)\n",
    "        self.embed_item_GMF = nn.Embedding(item_num, factor_num)\n",
    "        self.embed_user_MLP = nn.Embedding(user_num, factor_num * (2 ** (num_layers - 1)))\n",
    "        self.embed_item_MLP = nn.Embedding(item_num, factor_num * (2 ** (num_layers - 1)))\n",
    "\n",
    "        MLP_modules = []\n",
    "        for i in range(num_layers):\n",
    "            input_size = factor_num * (2 ** (num_layers - i))\n",
    "            MLP_modules.append(nn.Dropout(p=self.dropout))\n",
    "            MLP_modules.append(nn.Linear(input_size, input_size//2))\n",
    "            MLP_modules.append(nn.ReLU())\n",
    "        self.MLP_layers = nn.Sequential(*MLP_modules)\n",
    "\n",
    "        if self.model in ['MLP', 'GMF']:\n",
    "            predict_size = factor_num \n",
    "        else:\n",
    "            predict_size = factor_num * 2\n",
    "        self.predict_layer = nn.Linear(predict_size, 1)\n",
    "\n",
    "        self._init_weight_()\n",
    "    def _init_weight_(self):\n",
    "        \"\"\" 权重初始化\"\"\"\n",
    "        if not self.model == 'NeuMF-pre':\n",
    "            nn.init.normal_(self.embed_user_GMF.weight, std=0.01)\n",
    "            nn.init.normal_(self.embed_user_MLP.weight, std=0.01)\n",
    "            nn.init.normal_(self.embed_item_GMF.weight, std=0.01)\n",
    "            nn.init.normal_(self.embed_item_MLP.weight, std=0.01)\n",
    "\n",
    "            for m in self.MLP_layers:\n",
    "                if isinstance(m, nn.Linear):\n",
    "                    nn.init.xavier_uniform_(m.weight)\n",
    "            nn.init.kaiming_uniform_(self.predict_layer.weight, a=1, nonlinearity='sigmoid')\n",
    "\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "        else:\n",
    "            # embedding layers\n",
    "            self.embed_user_GMF.weight.data.copy_(self.GMF_model.embed_user_GMF.weight)\n",
    "            self.embed_item_GMF.weight.data.copy_(self.GMF_model.embed_item_GMF.weight)\n",
    "            self.embed_user_MLP.weight.data.copy_(self.MLP_model.embed_user_MLP.weight)\n",
    "            self.embed_item_MLP.weight.data.copy_(self.MLP_model.embed_item_MLP.weight)\n",
    "\n",
    "            # mlp layers\n",
    "            for (m1, m2) in zip(\n",
    "                self.MLP_layers, self.MLP_model.MLP_layers):\n",
    "                if isinstance(m1, nn.Linear) and isinstance(m2, nn.Linear):\n",
    "                    m1.weight.data.copy_(m2.weight)\n",
    "                    m1.bias.data.copy_(m2.bias)\n",
    "            # predict layers\n",
    "            predict_weight = torch.cat([\n",
    "                self.GMF_model.predict_layer.weight, \n",
    "                self.MLP_model.predict_layer.weight], dim=1)\n",
    "            precit_bias = self.GMF_model.predict_layer.bias + self.MLP_model.predict_layer.bias\n",
    "\n",
    "            self.predict_layer.weight.data.copy_(0.5 * predict_weight)\n",
    "            self.predict_layer.bias.data.copy_(0.5 * precit_bias)\n",
    "    def forward(self, user, item):\n",
    "        if not self.model == 'MLP':\n",
    "            embed_user_GMF = self.embed_user_GMF(user)\n",
    "            embed_item_GMF = self.embed_item_GMF(item)\n",
    "            output_GMF = embed_user_GMF * embed_item_GMF\n",
    "        if not self.model == 'GMF':\n",
    "            embed_user_MLP = self.embed_user_MLP(user)\n",
    "            embed_item_MLP = self.embed_item_MLP(item)\n",
    "            interaction = torch.cat((embed_user_MLP, embed_item_MLP), -1)\n",
    "            output_MLP = self.MLP_layers(interaction)\n",
    "\n",
    "        if self.model == 'GMF':\n",
    "            concat = output_GMF\n",
    "        elif self.model == 'MLP':\n",
    "            concat = output_MLP\n",
    "        else:\n",
    "            concat = torch.cat((output_GMF, output_MLP), -1)\n",
    "\n",
    "        prediction = self.predict_layer(concat)\n",
    "        return prediction.view(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b6f5ca2-ff3d-4200-93da-99f15d8b3c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = NCF(user_num, item_num, args.factor_num, args.num_layers, args.dropout, args.model, args.GMF_model, args.MLP_model)\n",
    "Model.to(args.device)\n",
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "\n",
    "if args.model == 'NeuMF-pre':\n",
    "    optimizer = optim.SGD(Model.parameters(), lr=args.lr)\n",
    "else:\n",
    "    optimizer = optim.Adam(Model.parameters(), lr=args.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72f682a0-9c6a-470c-9c58-84b59d43032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCFData(data.Dataset):\n",
    "    def __init__(self, features, \n",
    "                num_item, train_mat=None, num_ng=0, is_training=None):\n",
    "        super(NCFData, self).__init__()\n",
    "        \"\"\" Note that the labels are only useful when training, we thus \n",
    "            add them in the ng_sample() function.\n",
    "        \"\"\"\n",
    "        self.features_ps = features\n",
    "        self.num_item = num_item\n",
    "        self.train_mat = train_mat\n",
    "        self.num_ng = num_ng\n",
    "        self.is_training = is_training\n",
    "        self.labels = [0 for _ in range(len(features))]\n",
    "    def ng_sample(self):\n",
    "        assert self.is_training, 'no need to sampling when testing'\n",
    "\n",
    "        self.features_ng = []\n",
    "        for x in self.features_ps:\n",
    "            u = x[0]\n",
    "            for t in range(self.num_ng):\n",
    "                j = np.random.randint(self.num_item)\n",
    "                while (u, j) in self.train_mat:\n",
    "                    j = np.random.randint(self.num_item)\n",
    "                self.features_ng.append([u, j])\n",
    "\n",
    "        labels_ps = [1 for _ in range(len(self.features_ps))]\n",
    "        labels_ng = [0 for _ in range(len(self.features_ng))]\n",
    "\n",
    "        self.features_fill = self.features_ps + self.features_ng\n",
    "        self.labels_fill = labels_ps + labels_ng\n",
    "    def __len__(self):\n",
    "        return (self.num_ng + 1) * len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        features = self.features_fill if self.is_training else self.features_ps\n",
    "        labels = self.labels_fill if self.is_training else self.labels\n",
    "\n",
    "        user = features[idx][0]\n",
    "        item = features[idx][1]\n",
    "        label = labels[idx]\n",
    "        return user, item ,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e4c8ec5-8215-4133-9277-afcf6acfad38",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = NCFData(\n",
    "        train_data, item_num, train_mat, args.num_ng, True)\n",
    "test_dataset = NCFData(\n",
    "        test_data, item_num, train_mat, 0, False)\n",
    "train_loader = data.DataLoader(train_dataset,\n",
    "        batch_size=args.batch_size, shuffle=True, num_workers=0)\n",
    "test_loader = data.DataLoader(test_dataset,\n",
    "        batch_size=args.test_num_ng+1, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bcd86be-3dff-4e07-a6bb-4059f972b8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit(gt_item, pred_items):\n",
    "    if gt_item in pred_items:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "def ndcg(gt_item, pred_items):\n",
    "    if gt_item in pred_items:\n",
    "        index = pred_items.index(gt_item)\n",
    "        return np.reciprocal(np.log2(index+2))\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa465f96-1c06-4a2d-96c2-7082cfee5881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End. Best epoch 001: HR = 0.277, NDCG = 0.152\n"
     ]
    }
   ],
   "source": [
    "best_hr = 0\n",
    "hrs, ndcgs = [], []\n",
    "Loss = []\n",
    "Time = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime())\n",
    "with open('./NeuMF-work/' + Time + '.log', 'w') as f:\n",
    "    for epoch in range(args.epochs):\n",
    "        count, Sum = 0, 0\n",
    "        Model.train() # Enable dropout (if have).\n",
    "        start_time = time.time()\n",
    "        train_loader.dataset.ng_sample()\n",
    "\n",
    "        for user, item, label in train_loader:\n",
    "            user = user.to(args.device)\n",
    "            item = item.to(args.device)\n",
    "            label = label.float().to(args.device)\n",
    "            Model.zero_grad()\n",
    "            prediction = Model(user, item)\n",
    "            loss = loss_function(prediction, label)\n",
    "            Sum += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # writer.add_scalar('data/loss', loss.item(), count)\n",
    "            count += 1\n",
    "        Loss.append(Sum / count)\n",
    "        Model.eval()\n",
    "        HR, NDCG = metrics(Model, test_loader, args.top_k)\n",
    "        hrs.append(HR)\n",
    "        ndcgs.append(NDCG)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        f.write(\"The time elapse of epoch {:03d}\".format(epoch) + \" is: \" + time.strftime(\"%H: %M: %S\", time.gmtime(elapsed_time)) + \"\\n\")\n",
    "        f.write(\"HR: {:.3f}\\tNDCG: {:.3f}\\tLoss: {:.3f}\\n\".format(HR, NDCG, Loss[epoch]))\n",
    "#         print(\"The time elapse of epoch {:03d}\".format(epoch) + \" is: \" + \n",
    "#                 time.strftime(\"%H: %M: %S\", time.gmtime(elapsed_time)))\n",
    "        if HR > best_hr:\n",
    "            best_hr, best_ndcg, best_epoch = HR, NDCG, epoch\n",
    "            if args.out:\n",
    "                if not os.path.exists(args.model_path):\n",
    "                    os.mkdir(args.model_path)\n",
    "                torch.save(Model, '{}{}.pth'.format(args.model_path, args.model))\n",
    "\n",
    "print(\"End. Best epoch {:03d}: HR = {:.3f}, NDCG = {:.3f}\".format(best_epoch, best_hr, best_ndcg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e490e6-d3e5-4754-b763-455e1c725574",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch1.7",
   "language": "python",
   "name": "pytorch1.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
