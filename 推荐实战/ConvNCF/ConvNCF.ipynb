{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf939372-8acb-46c5-875b-9d813f379531",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ana\\envs\\pytorch1.7\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import json\n",
    "import random\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83a4aca6-8af8-44ee-826f-f6bd25065359",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Load_data():\n",
    "\n",
    "    def __init__(self, train_rating_path, test_rating_path, test_negative_path):\n",
    "        self.train_rating = self.load_rating(train_rating_path)\n",
    "        self.test_rating = self.load_rating(test_rating_path)\n",
    "        # self.test_negative = self.load_test_negative_from_file(test_negative_path)\n",
    "        self.test_negative = self.load_test_negative(test_negative_path)\n",
    "        self.train_group = self.get_train_group()\n",
    "\n",
    "    def load_test_negative(self, path):\n",
    "        test_negative = {}\n",
    "        data = np.loadtxt(path, delimiter='\\t', dtype='str')\n",
    "        records = len(data)\n",
    "        # print(data[0][1])\n",
    "        for i in range(records):\n",
    "            test_negative[int(data[i][0])] = eval(data[i][1])\n",
    "        return test_negative\n",
    "\n",
    "    def load_rating(self, path):\n",
    "        rating = np.loadtxt(path, delimiter='\\t')\n",
    "        record_count = len(rating[:, 0])\n",
    "        user_count = int(max(rating[:, 0])) + 1\n",
    "        item_count = int(max(rating[:, 1])) + 1\n",
    "        print('Loaded:', path)\n",
    "        print('Num of users:', user_count)\n",
    "        print('Num of items:', item_count)\n",
    "        print('Data sparsity:', record_count / (user_count * item_count))\n",
    "        # remove the last column: timestamp\n",
    "        return torch.from_numpy(rating[:, :-2])\n",
    "\n",
    "    def get_train_group(self):\n",
    "        neg = {}    \n",
    "        # get negative samples\n",
    "        if os.path.exists('data/train_neg_dict.json'):\n",
    "            neg = self.load_neg_dict_from_json('data/train_neg_dict.json')            \n",
    "        else:\n",
    "            neg = self.get_negative(self.train_rating, 100)\n",
    "            self.save_neg_dict_to_json(neg, 'data/train_neg_dict.json')\n",
    "\n",
    "        # save negative sample for resampling\n",
    "        self.train_negative = neg\n",
    "        \n",
    "        record_count = len(self.train_rating[:, 0])\n",
    "        groups = []\n",
    "        for r in range(record_count):\n",
    "            u = int(self.train_rating[r, 0])\n",
    "            i = int(self.train_rating[r, 1])\n",
    "            j = int(random.sample(neg[u], 1)[0])\n",
    "            groups.append([u, i, j])\n",
    "        return torch.tensor(groups)\n",
    "\n",
    "    def resample_train_group(self):\n",
    "        record_count = len(self.train_rating[:, 0])\n",
    "        groups = []\n",
    "        for r in range(record_count):\n",
    "            u = int(self.train_rating[r, 0])\n",
    "            i = int(self.train_rating[r, 1])\n",
    "            j = int(random.sample(self.train_negative[u], 1)[0])\n",
    "            groups.append([u, i, j])\n",
    "        return torch.tensor(groups)\n",
    "        \n",
    "    def get_negative(self, data, sample_count):\n",
    "        print('Calculating negative samples...')\n",
    "        neg = {}\n",
    "        record_count = len(data[:, 0])\n",
    "        user_count = int(max(data[:, 0])) + 1\n",
    "        item_count = int(max(data[:, 1])) + 1\n",
    "        for u in range(user_count):\n",
    "            neg[u] = []\n",
    "        last_u = 0\n",
    "        neg[0] = set(range(item_count))\n",
    "        # record_count = 100\n",
    "        for r in tqdm(range(record_count)):\n",
    "            u = int(data[r, 0])\n",
    "            if u != last_u:\n",
    "                neg[last_u] = random.sample(list(neg[last_u]), sample_count)\n",
    "                neg[u] = set(range(item_count))\n",
    "            last_u = u\n",
    "            i = int(data[r, 1])\n",
    "            neg[u] = neg[u] - set([i])\n",
    "        # neg[last_u] = set(range(item_count))\n",
    "        neg[last_u] = random.sample(list(neg[last_u]), sample_count)\n",
    "\n",
    "        return neg\n",
    "\n",
    "    def load_test_negative_from_file(self, path):\n",
    "        result = {}\n",
    "        neg = np.loadtxt('data/test.negative', delimiter='\\t', dtype='str')\n",
    "        print('Loaded:', path)\n",
    "        print('1000 negative test cases for each user')\n",
    "        record_count = len(neg)\n",
    "        for r in tqdm(range(record_count)):\n",
    "            ui = tuple(map(int, neg[r, 0][1:-1].split(',')))\n",
    "            u = ui[0]\n",
    "            i = ui[1]\n",
    "            if u not in result:\n",
    "                result[u] = []\n",
    "            else:\n",
    "                result[u].append(list(map(int, neg[r, 1:])))\n",
    "                result[u].append(i)\n",
    "        return result\n",
    "\n",
    "\n",
    "    def save_neg_dict_to_json(self, neg, path):\n",
    "        print('Saving negative samples to file:', path)\n",
    "        with open(path, \"w\") as f:\n",
    "            json.dump(neg, f, sort_keys=True)\n",
    "    \n",
    "    def save_neg_dict_to_pickle(self, neg, path):\n",
    "        print('Saving negative samples to file:', path)\n",
    "        with open(path, \"wb\") as f:\n",
    "            pickle.dump(neg, f)\n",
    "\n",
    "    def load_neg_dict_from_json(self, path):\n",
    "        print('Loading negative samples from file', path)\n",
    "        with open(path, 'r') as f:\n",
    "            d = json.load(f)\n",
    "            keys = list(map(int, d.keys()))\n",
    "            neg = {}\n",
    "            for i in range(len(keys)):\n",
    "                neg[keys[i]] = list(d.values())[i]\n",
    "            return neg\n",
    "\n",
    "    def load_neg_dict_from_pickle(self, path):\n",
    "        print('Loading negative samples from file', path)\n",
    "        with open(path, 'rb') as f:\n",
    "            return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ab86377-a9a5-4e4c-9c91-57c3ae621125",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config():\n",
    "    def __init__(self):\n",
    "        self.DEBUG = True\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.lr = 0.03\n",
    "        self.epoches = 2 if self.DEBUG else 50\n",
    "        self.batch_size = 512\n",
    "        self.train_path = 'data/train.rating'\n",
    "        self.test_path = 'data/test.rating'\n",
    "        self.test_negative_path = 'data/test.negative'\n",
    "args = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78d31f07-b49a-4707-92b6-960216ec5920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading...\n",
      "Loaded: data/train.rating\n",
      "Num of users: 943\n",
      "Num of items: 1152\n",
      "Data sparsity: 0.08930017968657948\n",
      "Loaded: data/test.rating\n",
      "Num of users: 943\n",
      "Num of items: 1148\n",
      "Data sparsity: 0.0008710801393728223\n",
      "Loading negative samples from file data/train_neg_dict.json\n"
     ]
    }
   ],
   "source": [
    "print('Data loading...')\n",
    "data = Load_data(args.train_path, args.test_path, args.test_negative_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3663c334-dd85-4c14-b169-6025bb27241f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNCF(nn.Module):\n",
    "\n",
    "    def __init__(self, user_count, item_count):\n",
    "        super(ConvNCF, self).__init__()\n",
    "\n",
    "        self.user_count = user_count\n",
    "        self.item_count = item_count\n",
    "\n",
    "        self.embedding_size = 64\n",
    "\n",
    "        self.P = nn.Embedding(self.user_count, self.embedding_size).to(args.device)\n",
    "        self.Q = nn.Embedding(self.item_count, self.embedding_size).to(args.device)\n",
    "\n",
    "        # cnn 定义及参数\n",
    "        self.channel_size = 32\n",
    "        self.kernel_size = 2\n",
    "        self.strides = 2\n",
    "        self.cnn = nn.Sequential(\n",
    "            # batch_size * 1 * 64 * 64\n",
    "            nn.Conv2d(1, self.channel_size, self.kernel_size, stride=self.strides),\n",
    "            nn.ReLU(),\n",
    "            # batch_size * 32 * 32 * 32\n",
    "            nn.Conv2d(self.channel_size, self.channel_size, self.kernel_size, stride=self.strides),\n",
    "            nn.ReLU(),\n",
    "            # batch_size * 32 * 16 * 16\n",
    "            nn.Conv2d(self.channel_size, self.channel_size, self.kernel_size, stride=self.strides),\n",
    "            nn.ReLU(),\n",
    "            # batch_size * 32 * 8 * 8\n",
    "            nn.Conv2d(self.channel_size, self.channel_size, self.kernel_size, stride=self.strides),\n",
    "            nn.ReLU(),\n",
    "            # batch_size * 32 * 4 * 4\n",
    "            nn.Conv2d(self.channel_size, self.channel_size, self.kernel_size, stride=self.strides),\n",
    "            nn.ReLU(),\n",
    "            # batch_size * 32 * 2 * 2\n",
    "            nn.Conv2d(self.channel_size, self.channel_size, self.kernel_size, stride=self.strides),\n",
    "            nn.ReLU(),\n",
    "            # batch_size * 32 * 1 * 1\n",
    "        )\n",
    "        # 全连接层定义\n",
    "        self.fc = nn.Linear(32, 1)\n",
    "    def forward(self, user_ids, item_ids, is_pretrain):\n",
    "\n",
    "        user_ids = list(map(int, user_ids))\n",
    "        item_ids = list(map(int, item_ids))\n",
    "\n",
    "        user_embeddings = self.P(torch.tensor(user_ids).to(args.device))\n",
    "        item_embeddings = self.Q(torch.tensor(item_ids).to(args.device))\n",
    "        \n",
    "        if is_pretrain:\n",
    "            # 内积\n",
    "            prediction = torch.sum(torch.mul(user_embeddings, item_embeddings), dim=1)\n",
    "        else:\n",
    "            # 外积\n",
    "            interaction_map = torch.bmm(user_embeddings.unsqueeze(2), item_embeddings.unsqueeze(1))\n",
    "            interaction_map = interaction_map.view((-1, 1, self.embedding_size, self.embedding_size))\n",
    "\n",
    "            # cnn\n",
    "            feature_map = self.cnn(interaction_map)  # output: batch_size * 32 * 1 * 1\n",
    "            feature_vec = feature_map.view((-1, 32))\n",
    "            prediction = self.fc(feature_vec)\n",
    "            prediction = prediction.view((-1))\n",
    "\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e13245d8-33e7-4a59-b670-6079f9ce3c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义BPR损失函数\n",
    "class BPRLoss(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(BPRLoss, self).__init__()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, pos_preds, neg_preds):\n",
    "        distance = pos_preds - neg_preds\n",
    "        loss = torch.sum(torch.log((1 + torch.exp(-distance))))\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2fd6877d-eb6e-417f-b6a5-aa4a4198eebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNCF(int(max(data.train_group[:, 0])) + 1, int(max(data.train_group[:, 1])) + 1)\n",
    "model = model.to(args.device)\n",
    "optimizer = optim.Adagrad(model.parameters(), lr = args.lr, weight_decay=1e-2)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1, last_epoch=-1)\n",
    "bpr_loss = BPRLoss().to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba71cc62-85eb-4942-a28d-b68f93452df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = Data.DataLoader(data.train_group, batch_size = args.batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1526d755-d37b-45c4-8c0b-4efb86f1530e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#评价指标br、ndcg\n",
    "def scoreK(topi, k):\n",
    "    hr = 1.0 if 99 in topi[0:k] else 0.0\n",
    "    if hr:\n",
    "        ndcg = math.log(2) / math.log(topi.tolist().index(99) + 2)\n",
    "    else:\n",
    "        ndcg = 0\n",
    "    return hr, ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d20fbdc-8079-4f1d-8f4d-56dd0902e33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hr10 = []\n",
    "ndcg10 = []\n",
    "best_hr, best_ndcg = 0, 0\n",
    "model_path = ''\n",
    "#模型评价函数\n",
    "def evaluate(epoch):\n",
    "    global best_hr, best_ndcg, model_path\n",
    "    model.eval()\n",
    "    user_count = len(data.test_negative)\n",
    "    hrs = []\n",
    "    ndcgs = []\n",
    "    for u in range(user_count):\n",
    "\n",
    "        item_ids = torch.tensor(data.test_negative[u]).to(args.device)\n",
    "        user_ids = torch.tensor([u] * len(item_ids)).to(args.device)\n",
    "        predictions = model(user_ids, item_ids, False)\n",
    "        topv, topi = torch.topk(predictions, 10, dim=0)\n",
    "        hr, ndcg = scoreK(topi, 10)\n",
    "        hrs.append(hr)\n",
    "        ndcgs.append(ndcg)\n",
    "    with open('./ConvNCF-work/{}.log'.format(Time), 'a+') as f:\n",
    "        f.write('HR@10:{:.4f},\\tNDCG@10:{:.4f}\\n'.format(sum(hrs) / len(hrs), sum(ndcgs) / len(ndcgs)))\n",
    "\n",
    "    hr10.append(sum(hrs) / len(hrs))\n",
    "    ndcg10.append(sum(ndcgs) / len(ndcgs))\n",
    "    if sum(hrs) / len(hrs) > best_hr:\n",
    "        best_hr, best_ndcg = sum(hrs) / len(hrs), sum(ndcgs) / len(ndcgs)\n",
    "        model_path = './ConvNCF-temp/{}_epoch{}.model'.format(Time, epoch)    \n",
    "        torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "228bcf9f-bf00-4be0-be8f-11ec3046a266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train...\n",
      "Done...\n",
      "best_hr:0.08059384941675504\tbest_ndcg:0.037491862987662786\n",
      "The best model is saved to ./ConvNCF-temp/2023-02-13-20-43-05_epoch0.model\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "accuracies = []\n",
    "model.train()\n",
    "Time = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime())\n",
    "print('train...')\n",
    "for epoch in range(args.epoches):    \n",
    "\n",
    "    t1 = time.time()\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "\n",
    "    for batch_idx, train_data in enumerate(train_loader):                    \n",
    "        user_ids = Variable(train_data[:, 0].to(args.device))\n",
    "        pos_item_ids = Variable(train_data[:, 1].to(args.device))\n",
    "        neg_item_ids = Variable(train_data[:, 2].to(args.device))\n",
    "        optimizer.zero_grad()\n",
    "        if epoch < 10:    \n",
    "            #在前十轮首先预训练BPR，这个值可以自由设置\n",
    "            pos_preds = model(user_ids, pos_item_ids, True)\n",
    "            neg_preds = model(user_ids, neg_item_ids, True)                        \n",
    "        else:\n",
    "            #训练ConvNCF                        \n",
    "            pos_preds = model(user_ids, pos_item_ids, False)\n",
    "            neg_preds = model(user_ids, neg_item_ids, False)                        \n",
    "\n",
    "        loss = bpr_loss(pos_preds, neg_preds)                    \n",
    "        total_loss += loss.item()                    \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    t2 = time.time()\n",
    "    losses.append(total_loss / (batch_idx + 1))\n",
    "    with open('./ConvNCF-work/{}.log'.format(Time), 'a+') as f:\n",
    "        f.write('Epoch:{},\\tTrain loss:{:.4f},\\tTime:{:.4f}\\n'.format(epoch, losses[-1],  t2-t1))  \n",
    "    evaluate(epoch)\n",
    "    scheduler.step()\n",
    "\n",
    "print('Done...')\n",
    "print('best_hr:{}\\tbest_ndcg:{}'.format(best_hr, best_ndcg))\n",
    "print(\"The best model is saved to {}\".format(model_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc361ed-800a-4796-9d86-f536ddca40d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch1.7",
   "language": "python",
   "name": "pytorch1.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
