{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2aa84c69-f7f9-49e3-9ecc-ba454d92000e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ana\\envs\\pytorch1.7\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.autograd import Variable\n",
    "from torch.backends import cudnn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "from src.utils import collate_fn\n",
    "from src.dataset import load_data\n",
    "from src import metric\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5466653d-c931-45e1-b3bd-60f9a2fcd3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config():\n",
    "    def __init__(self):\n",
    "        self.DEBUG = True\n",
    "        self.dataset_path = 'data/ml-100k/'\n",
    "        self.batch_size = 512\n",
    "        self.hidden_size = 100 #gru\n",
    "        self.embed_dim = 50 #item embedding\n",
    "        self.epochs = 5 if self.DEBUG else 100\n",
    "        self.lr = 0.001\n",
    "        self.lr_dc = 0.1\n",
    "        self.lr_dc_step = 80\n",
    "        self.topk = 20\n",
    "        self.valid_portion = 0.2\n",
    "        self.test = True #控制模型是否进行加载、测试的参数\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "args = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "509f6ee7-4ac6-4747-a08f-b1522d6f230d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Starting @ 2023-02-13 20:04:39.799690s\n",
      "-- Reading data @ 2023-02-13 20:04:40.296711s\n",
      "Splitting date 890694638\n",
      "训练集session数量:\t1636\n",
      "测试集session数量:\t327\n",
      "-- Splitting train set and test set @ 2023-02-13 20:04:40.359684s\n",
      "item number:\t1342\n",
      "训练集序列数:\t80737\n",
      "测试集序列数:\t16157\n",
      "序列的avg length:  50.48621041879469\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "!python ./src/preprocess.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac768533-3a5d-4f19-a816-37fbb692301f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "print('Loading data...')\n",
    "train, valid, test = load_data(args.dataset_path, valid_portion = args.valid_portion)\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caa9e273-cd66-4d06-a707-0f79ca60b68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NARM(nn.Module):\n",
    "    def __init__(self, n_items, hidden_size, embedding_dim, batch_size, n_layers = 1):\n",
    "        super(NARM, self).__init__()\n",
    "        self.n_items = n_items\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.emb = nn.Embedding(self.n_items, self.embedding_dim, padding_idx = 0)\n",
    "        self.emb_dropout = nn.Dropout(0.25)\n",
    "        self.gru = nn.GRU(self.embedding_dim, self.hidden_size, self.n_layers)\n",
    "        self.a_1 = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.a_2 = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.v_t = nn.Linear(self.hidden_size, 1, bias=False)\n",
    "        self.ct_dropout = nn.Dropout(0.5)\n",
    "        self.b = nn.Linear(self.embedding_dim, 2 * self.hidden_size, bias=False)\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    def forward(self, seq, lengths):\n",
    "        hidden = self.init_hidden(seq.size(1))\n",
    "        embs = self.emb_dropout(self.emb(seq))\n",
    "        embs = pack_padded_sequence(embs, lengths)\n",
    "        gru_out, hidden = self.gru(embs, hidden)\n",
    "        gru_out, lengths = pad_packed_sequence(gru_out)\n",
    "\n",
    "        ht = hidden[-1]\n",
    "        gru_out = gru_out.permute(1, 0, 2)\n",
    "\n",
    "        c_global = ht\n",
    "        q1 = self.a_1(gru_out.contiguous().view(-1, self.hidden_size)).view(gru_out.size())  \n",
    "        q2 = self.a_2(ht)\n",
    "\n",
    "        mask = torch.where(seq.permute(1, 0) > 0, torch.tensor([1.], device = self.device), torch.tensor([0.], device = self.device))\n",
    "        q2_expand = q2.unsqueeze(1).expand_as(q1)\n",
    "        q2_masked = mask.unsqueeze(2).expand_as(q1) * q2_expand\n",
    "        \n",
    "        alpha = self.v_t(torch.sigmoid(q1 + q2_masked).view(-1, self.hidden_size)).view(mask.size())\n",
    "        c_local = torch.sum(alpha.unsqueeze(2).expand_as(gru_out) * gru_out, 1)\n",
    "\n",
    "        c_t = torch.cat([c_local, c_global], 1)\n",
    "        c_t = self.ct_dropout(c_t)\n",
    "        \n",
    "        item_embs = self.emb(torch.arange(self.n_items).to(self.device))\n",
    "        scores = torch.matmul(c_t, self.b(item_embs).permute(1, 0))\n",
    "\n",
    "        return scores\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros((self.n_layers, batch_size, self.hidden_size), requires_grad=True).to(self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68b7d27f-27db-455d-9aa4-695231df7454",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_items = 1342\n",
    "model = NARM(n_items, args.hidden_size, args.embed_dim, args.batch_size).to(args.device)\n",
    "optimizer = optim.Adam(model.parameters(), args.lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = StepLR(optimizer, step_size = args.lr_dc_step, gamma = args.lr_dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b96af05d-06ea-4e74-8c47-88ed6e12dc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecSysDataset(Dataset):\n",
    "    \"\"\"define the pytorch Dataset class for yoochoose and diginetica datasets.\n",
    "    \"\"\"\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        print('-'*50)\n",
    "        print('Dataset info:')\n",
    "        print('Number of sessions: {}'.format(len(data[0])))\n",
    "        print('-'*50)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        session_items = self.data[0][index]\n",
    "        target_item = self.data[1][index]\n",
    "        return session_items, target_item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1801006-d2a5-49b1-b880-f29b150f2264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 64590\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 16147\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Dataset info:\n",
      "Number of sessions: 16157\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "train_data = RecSysDataset(train)\n",
    "valid_data = RecSysDataset(valid)\n",
    "test_data = RecSysDataset(test)\n",
    "train_loader = DataLoader(train_data, batch_size = args.batch_size, shuffle = True, collate_fn = collate_fn)\n",
    "valid_loader = DataLoader(valid_data, batch_size = args.batch_size, shuffle = False, collate_fn = collate_fn)\n",
    "test_loader = DataLoader(test_data, batch_size = args.batch_size, shuffle = False, collate_fn = collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d165de3-da6e-47f3-be31-18b1aa023b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss = []\n",
    "def trainForEpoch(train_loader, model, optimizer, epoch, num_epochs, criterion):\n",
    "    global Time\n",
    "    model.train()\n",
    "\n",
    "    sum_epoch_loss = 0\n",
    "    start = time.time()\n",
    "    for i, (seq, target, lens) in enumerate(train_loader):\n",
    "        seq = seq.to(args.device)\n",
    "        target = target.to(args.device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(seq, lens)\n",
    "        loss = criterion(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "\n",
    "        loss_val = loss.item()\n",
    "        sum_epoch_loss += loss_val\n",
    "    Loss.append(sum_epoch_loss / len(train_loader))\n",
    "    with open('./NARM-work/{}.log'.format(Time), 'a+') as f:\n",
    "        f.write('[TRAIN] epoch %d/%d\\tloss: %.4f\\t(%.2f im/s)\\n'\n",
    "        % (epoch + 1, num_epochs, sum_epoch_loss / len(train_loader), time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee30e092-b3b0-4b84-abd7-66d42d7b89db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#评价函数的定义\n",
    "def validate(valid_loader, model):\n",
    "    model.eval()\n",
    "    recalls = []\n",
    "    mrrs = []\n",
    "    with torch.no_grad():\n",
    "        for seq, target, lens in valid_loader:\n",
    "            seq = seq.to(args.device)\n",
    "            target = target.to(args.device)\n",
    "            outputs = model(seq, lens)\n",
    "            logits = F.softmax(outputs, dim = 1)\n",
    "            recall, mrr = metric.evaluate(logits, target, k = args.topk)\n",
    "            recalls.append(recall)\n",
    "            mrrs.append(mrr)\n",
    "    \n",
    "    mean_recall = np.mean(recalls)\n",
    "    mean_mrr = np.mean(mrrs)\n",
    "    return mean_recall, mean_mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f62dd0c-6562-4084-9899-2c6689b8cf4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n",
      "Done...\n"
     ]
    }
   ],
   "source": [
    "Time = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime())\n",
    "recalls = []\n",
    "best_re = 0.0\n",
    "print('training...')\n",
    "for epoch in range(args.epochs):\n",
    "    # train for one epoch\n",
    "    scheduler.step(epoch = epoch)\n",
    "    trainForEpoch(train_loader, model, optimizer, epoch, args.epochs, criterion)\n",
    "\n",
    "    recall, mrr = validate(valid_loader, model)\n",
    "    recalls.append(recall)\n",
    "    with open('./NARM-work/{}.log'.format(Time), 'a+') as f:\n",
    "        f.write('Epoch {} validation: Recall@{}: {:.4f},\\tMRR@{}: {:.4f} \\n\\n'.format(epoch, args.topk, recall, args.topk, mrr))\n",
    "\n",
    "    # 模型存储信息\n",
    "    ckpt_dict = {\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict()\n",
    "    }\n",
    "    ckpt_dict = {\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict()\n",
    "    }\n",
    "    if recall > best_re:\n",
    "        best_re = recall\n",
    "        torch.save(ckpt_dict, './NARM-temp/{}_{}.pth.tar'.format(Time, best_re))\n",
    "print('Done...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4a419c6-d60d-4858-b369-747eefd49df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Recall@20: 0.0930, MRR@20: 0.0205\n"
     ]
    }
   ],
   "source": [
    "if test:\n",
    "    ckpt = torch.load('./NARM-temp/{}_{}.pth.tar'.format(Time, best_re))\n",
    "    model.load_state_dict(ckpt['state_dict'])\n",
    "    recall, mrr = validate(test_loader, model)\n",
    "    print(\"Test: Recall@{}: {:.4f}, MRR@{}: {:.4f}\".format(args.topk, recall, args.topk, mrr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2ccf9c-432c-4e7e-ab0d-37f56735c042",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7c9ce6-e496-4a69-b71b-2f885ee07f3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch1.7",
   "language": "python",
   "name": "pytorch1.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
